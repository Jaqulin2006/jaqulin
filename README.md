import random
import nltk
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.naive_bayes import MultinomialNB

# Download NLTK data (only first time)
nltk.download('punkt')

# Sample dataset of intents and responses
intents = {
    'greeting': {
        'patterns': ['Hi', 'Hello', 'Is anyone there?', 'Hey', 'Good day'],
        'responses': ['Hello!', 'Hi there!', 'How can I help you today?']
    },
    'goodbye': {
        'patterns': ['Bye', 'See you later', 'Goodbye'],
        'responses': ['Goodbye!', 'See you soon!', 'Have a great day!']
    },
    'thanks': {
        'patterns': ['Thanks', 'Thank you', 'That helps'],
        'responses': ['Happy to help!', 'Anytime!', 'Youâ€™re welcome!']
    },
    'noanswer': {
        'patterns': [],
        'responses': ['Sorry, I did not understand that.', 'Can you please rephrase?']
    },
    'order_status': {
        'patterns': ['Where is my order?', 'Order status', 'Track my order'],
        'responses': ['Please provide your order ID to track the status.']
    },
    'refund': {
        'patterns': ['I want a refund', 'How do I get a refund?', 'Refund status'],
        'responses': ['You can request a refund from your order history page.']
    }
}

# Prepare training data
all_patterns = []
all_labels = []

for intent, data in intents.items():
    for pattern in data['patterns']:
        all_patterns.append(pattern.lower())
        all_labels.append(intent)

# Vectorize text data
vectorizer = CountVectorizer()
X = vectorizer.fit_transform(all_patterns)

# Train classifier
clf = MultinomialNB()
clf.fit(X, all_labels)

# Chatbot response function
def chatbot_response(user_input):
    user_input = user_input.lower()
    X_test = vectorizer.transform([user_input])
    pred = clf.predict(X_test)[0]

    if pred in intents:
        return random.choice(intents[pred]['responses'])
    else:
        return random.choice(intents['noanswer']['responses'])

# Run the chatbot
print("Customer Support Chatbot (type 'quit' to exit)")
while True:
    user_input = input("You: ")
    if user_input.lower() == 'quit':
        print("Chatbot: Goodbye!")
        break
    response = chatbot_response(user_input)
    print(f"Chatbot: {response}")

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1WXwD0BwizkSce6i9bCvOhibsgUHzA1aQ
"""

from transformers import pipeline

class CustomerSupportChatbot:
    def __init__(self):
        # Load a pre-trained conversational model
        self.chatbot = pipeline("conversational", model="microsoft/DialoGPT-medium")

    def chat(self):
        print("Welcome to Customer Support!")
        print("Type 'exit' to end the conversation.\n")

        conversation_history = []

        while True:
            user_input = input("You: ")
            if user_input.lower() == 'exit':
                print("Chatbot: Thank you for reaching out. Have a great day!")
                break

            # Process the user's input
            conversation_history.append(user_input)
            response = self.get_response(user_input)
            conversation_history.append(response)

            print(f"Chatbot: {response}")

    def get_response(self, user_input):
        # Generate a response using the chatbot model
        result = self.chatbot(user_input)
        return result[0]['generated_text']

if __name__ == "__main__":
    bot = CustomerSupportChatbot()
    bot.chat()

from transformers import pipeline, Conversation

class CustomerSupportChatbot:
    def __init__(self):
        # Load a pre-trained conversational model
        self.chatbot = pipeline("text-generation", model="microsoft/DialoGPT-medium")

    def chat(self):
        print("Welcome to Customer Support!")
        print("Type 'exit' to end the conversation.\n")

        conversation_history = []
        conversation = Conversation()

        while True:
            user_input = input("You: ")
            if user_input.lower() == 'exit':
                print("Chatbot: Thank you for reaching out. Have a great day!")
                break

            # Process the user's input
            conversation.add_user_input(user_input)
            response = self.get_response(conversation) # pass the conversation object
            conversation.append_response(response) # Update with the model response

            print(f"Chatbot: {response}")

    def get_response(self, conversation):
        # Generate a response using the chatbot model
        result = self.chatbot(conversation,  max_length=1000, pad_token_id=self.chatbot.tokenizer.eos_token_id)
        return result.generated_responses[-1]  # Get the last generated response


if __name__ == "__main__":
    bot = CustomerSupportChatbot()
    bot.chat()

from transformers import pipeline, GenerationConfig

class CustomerSupportChatbot:
    def __init__(self):
        # Load a pre-trained conversational model
        self.chatbot = pipeline("text-generation", model="microsoft/DialoGPT-medium")

    def chat(self):
        print("Welcome to Customer Support!")
        print("Type 'exit' to end the conversation.\n")

        conversation_history = []
        # Conversation is replaced with a list to store past interactions
        # conversation = Conversation()

        while True:
            user_input = input("You: ")
            
